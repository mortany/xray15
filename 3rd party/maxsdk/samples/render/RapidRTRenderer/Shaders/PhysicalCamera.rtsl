//////////////////////////////////////////////////////////////////////////////
//
//  Copyright 2015 Autodesk, Inc.  All rights reserved.
//
//  Use of this software is subject to the terms of the Autodesk license 
//  agreement provided at the time of installation or download, or which 
//  otherwise accompanies this software in either electronic or hard copy form.   
//
//////////////////////////////////////////////////////////////////////////////

shader PhysicalCamera : camera
{
    // Aspect ratio of the image: pixel_aspect * x_resolution / y_resolution
    uniform float m_image_aspect_ratio;
    uniform float m_one_over_image_aspect_ratio;
    // Width of the film plane in world space
    uniform float m_film_width;
    // Focus distance in world space
    uniform float m_focus_distance;
    // Lens focal length in world space
    uniform float m_lens_focal_length;
    // 1.0 / resolution
    uniform float2 m_one_over_resolution;

    uniform float2 m_film_offset_pixels;

    uniform float m_cubic_distortion_amount;
    uniform float2 m_tilt_amount;
    uniform float2 m_tilt_multiplier;

    uniform bool m_distortion_texture_enabled;
    uniform texture2D m_distortion_texture;

    uniform bool m_enable_dof;
    // Number of aperture blades for Bokeh. 0 == circular
    uniform int m_aperture_num_blades;
    uniform float m_aperture_blades_rotation_radians;
    // Exponent applied to radial sample to implement center bias
    // = 0.5f * ((center_bias > 0.0f) ? (1.0f / (1.0f + center_bias)) : (1.0f - center_bias));
    uniform float m_aperture_radial_exponent;
    // X and Y multipliers for aperture anisotropy
    uniform float2 m_aperture_anisotropy_mult;
    uniform float m_aperture_optical_vigneting;

    // Aperture bitmap sampler data generated by class IPhysicalCamera_BitmapApertureSampler
    uniform bool m_aperture_bitmap_enabled;
    uniform texture2D m_aperture_bitmap_pixel_weights;
    uniform texture2D m_aperture_bitmap_x_selection_cdf;
    uniform texture2D m_aperture_bitmap_y_selection_cdf;
    uniform int2 m_aperture_bitmap_resolution;

    // Clipping plane
    uniform float m_near_clip_distance;

    const float PI = 3.14159265;
    const float TWO_PI = (2.0 * PI);

    float3 make_float3(float2 v)
    {
        return float3(v.x, v.y, 0.0);
    }

    float3 make_float3(float2 v, float z)
    {
        return float3(v.x, v.y, z);
    }

    void generateRay()
    {
        // Process the distortion texture which remaps the raster space position
        if(m_distortion_texture_enabled)
        {
            float2 distortion_texture_uv = rt_RasterPosition * m_one_over_resolution;
            float2 distortion_texture_result = m_distortion_texture.lookup(distortion_texture_uv).rg;
            rt_RasterPosition = distortion_texture_result * float2(float(rt_ImageResolution.x), float(rt_ImageResolution.y));
        }

        // Apply film planet offset (lens shift)
        rt_RasterPosition -= m_film_offset_pixels;

        // Position on film plane, width film plane width bounded to [-0.5, 0.5] (though we can be out of bounds, if a film offset is applied)
        float2 film_position = ((rt_RasterPosition * m_one_over_resolution) - float2(0.5, 0.5)) * float2(1.0, m_one_over_image_aspect_ratio);
        float2 film_position_differential = (((rt_RasterPosition + float2(1.0, 1.0)) * m_one_over_resolution) - float2(0.5, 0.5)) * float2(1.0, m_one_over_image_aspect_ratio);

        // Calculate ray target on the focus plane
        float film_plane_mult = (m_film_width * m_focus_distance / m_lens_focal_length);
        float3 ray_target = make_float3(film_plane_mult * film_position, -m_focus_distance);
        float3 ray_target_differential = make_float3(film_plane_mult * film_position_differential, -m_focus_distance);

        // Parametric distortion modifies ray target
        if(m_cubic_distortion_amount != 0.0)
        {
            if(!apply_cubic_distortion(m_cubic_distortion_amount, film_position, ray_target))
            {
                // Sample rejected
                discard;
            }
        }

        // Tilt correction modifies ray target
        ray_target.x *= m_tilt_multiplier.x;
        ray_target.y *= m_tilt_multiplier.y;
        ray_target.z -= (ray_target.x * m_tilt_amount.x) + (ray_target.y * m_tilt_amount.y);

        // DOF: sample aperture
        if(m_enable_dof)
        {
            float2 aperture_sample_position;
            if(sample_aperture(aperture_sample_position, rt_LensSample, rt_ColorFilter, rt_RasterPosition))
            {
                // Apply aperture size
                aperture_sample_position *= rt_LensRadius;
                // Apply aperture offset to ray origin
                rt_RayOrigin += make_float3(aperture_sample_position);
                rt_RayOriginDX += make_float3(aperture_sample_position);
                rt_RayOriginDY += make_float3(aperture_sample_position);
            }
            else
            {
                // Aperture sample rejected
                discard;
            }
        }

        // Calculate the new ray direction
        rt_RayDirection = normalize(ray_target - rt_RayOrigin);
        rt_RayDirectionDX = normalize(float3(ray_target_differential.x, ray_target.y, ray_target_differential.z) - rt_RayOriginDX);
        rt_RayDirectionDY = normalize(float3(ray_target.x, ray_target_differential.y, ray_target_differential.z) - rt_RayOriginDY);

        // Apply clipping plane to origin
        if(abs(m_near_clip_distance) > 1e-6)
        {
            // Optimization of:
            //const float t = -(dot(rt_RayOrigin, float3(0.0, 0.0, 1.0)) + m_near_clip_distance) / dot(rt_RayDirection, float3(0.0, 0.0, 1.0));
            const float t = -(rt_RayOrigin.z + m_near_clip_distance) / rt_RayDirection.z;
            const float3 new_origin = rt_RayOrigin + t * rt_RayDirection;
            
            // Move the ray origin
            const float3 origin_differential = new_origin - rt_RayOrigin;
            rt_RayOriginDX += origin_differential;
            rt_RayOriginDY += origin_differential;
            rt_RayOrigin = new_origin;
        }
    }

    // Samples the aperture, returning the sample point as an offset to the center of the aperture, in [-1, 1]
    bool sample_aperture(
        out float2 sample_position, 
        float2 lens_sample, 
        inout float3 sample_weight,
        float2 raster_position)
    {
        // Radial sample, but will be adjusted for center bias effect
        float radial_position = pow(lens_sample.y, m_aperture_radial_exponent);

        if(!m_aperture_bitmap_enabled)
        {
            if(m_aperture_num_blades < 3)      // circular aperture
            {
                float theta = TWO_PI * lens_sample.x;
                sample_position = float2(cos(theta), sin(theta)) * radial_position;
            }
            else        // bladed aperture
            {
                // Determine segment to be sampled
                float blade_sample = lens_sample.x * float(m_aperture_num_blades);
                float segment_index = floor(blade_sample);
                // Rescale sample within segment
                blade_sample -= segment_index;

                float segment_angular_coverage = (TWO_PI / float(m_aperture_num_blades));
                // Angles for the two edges of the selected triangle
                float a0 = m_aperture_blades_rotation_radians + (segment_index * segment_angular_coverage);
                float a1 = a0 + segment_angular_coverage;

                float2 edge0 = float2(cos(a0), sin(a0));
                float2 edge1 = float2(cos(a1), sin(a1));
                sample_position = ((edge0 * (1.0 - blade_sample)) + (edge1 * blade_sample)) * radial_position;
            }
        }
        else        // bitmap aperture
        {
            // Sample a row
            float y_coord = sample_cdf_pixel(lens_sample.y, m_aperture_bitmap_y_selection_cdf, int2(m_aperture_bitmap_resolution.y, 1), 0);

            // Sample a x coordinate within the selected row
            float x_coord = sample_cdf_pixel(lens_sample.x, m_aperture_bitmap_x_selection_cdf, m_aperture_bitmap_resolution, int(y_coord));

            // Rescale sampled coordinate in [-1,1]
            float2 resolution = float2(float(m_aperture_bitmap_resolution.x), float(m_aperture_bitmap_resolution.y));
            sample_position = ((float2(x_coord, y_coord) / resolution) * 2.0) - float2(1.0, 1.0);
            sample_position.y = -sample_position.y;

            // Evaluate the aperture bitmap weight
            sample_weight *= lookup_array_texture_float3(m_aperture_bitmap_pixel_weights, int2(int(x_coord), int(y_coord)), m_aperture_bitmap_resolution);
        }

        // Process less anisotropy/anamorphism
        sample_position *= m_aperture_anisotropy_mult;

        // Process optical vignetting (cat eye effect)
        if(m_aperture_optical_vigneting != 0.0)
        {
            // Calculate position on film plane, in [-1, 1] (the range can go outside of [-1, 1] if there's a film plane offset)
            // For the y coordinate, we take the image aspect ratio into account, as the sensor aspect affects the effect of optical vignetting
            // We also take the film plane offset into account, as that will impact optical vignetting as well
            float2 film = ((raster_position * m_one_over_resolution * 2.0) - float2(1.0, 1.0)) * float2(1.0, m_image_aspect_ratio);
            // Optical vignetting clips sample points which are too far off to the side.
            // Unfortunately, there doesn't seem to be an efficient way to sample this effect, so we're forced to simply filter/reject samples.
            float2 distance_vector = (film * m_aperture_optical_vigneting) - sample_position;
            float distance_squared = (distance_vector.x * distance_vector.x) + (distance_vector.y * distance_vector.y);
            if(distance_squared > 1.0f)
            {
                // Reject the sample
                return false;
            }
        }

        return true;
    }

    // Function copied from IPhysicalCamera_BitmapApertureSampler::sample_cdf_pixel()
    float sample_cdf_pixel(
        // Random sample value
        float sample_value, 
        // Texture containing the array of data to be searched
        texture2D cdf_table,
        int2 cdf_table_resolution,
        // Row, in the texture, that contains the search range
        int search_row)
    {
        // Use binary search to find the first value that is greater than the sample value. 
        int current_range_first_index = 0;
        int current_range_last_index = cdf_table_resolution.x - 1;
        while((current_range_last_index - current_range_first_index) > 1)       // loop until there are either 1 or 2 elements left in the search range
        {
            int current_center_index = (current_range_first_index + current_range_last_index) / 2;
            float center_cdf_value = lookup_array_texture_float(cdf_table, int2(current_center_index, search_row), cdf_table_resolution);
            if(sample_value < center_cdf_value)
            {
                // Look left
                current_range_last_index = current_center_index;
            }
            else
            {
                // Look right
                current_range_first_index = current_center_index;
            }
        }

        // 1 or 2 elements left in the search range: determine which is the first to be grater than the sample value
        // (it's possible that no elements are greater than the sample value - thanks to precision issues - in which case we use the last element)
        float first_cdf_value = lookup_array_texture_float(cdf_table, int2(current_range_first_index, search_row), cdf_table_resolution);
        int search_result_index = (sample_value < first_cdf_value) ? current_range_first_index : current_range_last_index;

        // Rescale the sample to point to a position within the pixel, to be used as the fractional part of the texture coordinate
        float previous_cdf;
        if(search_result_index > 0)
        {
            previous_cdf = lookup_array_texture_float(cdf_table, int2(search_result_index - 1, search_row), cdf_table_resolution);
        }
        else
        {
            previous_cdf = 0.0;
        }
        float current_cdf = lookup_array_texture_float(cdf_table, int2(search_result_index, search_row), cdf_table_resolution);
        float rescaled_sample = min((sample_value - previous_cdf) / (current_cdf - previous_cdf), 1.0);     // clamp to 1.0 to avoid precision issues that could result in sampling last row that has entirely zeros

        return float(search_result_index) + rescaled_sample;
    }

    // Performs an array-index lookup in the texture that holds values. We use textures to store our values, but want these textures to behave like arrays.
    float3 lookup_array_texture_float3(texture2D array_texture, int2 coord, int2 texture_resolution)
    {
        float2 uv = (float2(float(coord.x), float(coord.y)) + float2(0.5, 0.5)) / float2(float(texture_resolution.x), float(texture_resolution.y));
        return array_texture.lookup(uv).rgb;
    }
    float lookup_array_texture_float(texture2D array_texture, int2 coord, int2 texture_resolution)
    {
        return lookup_array_texture_float3(array_texture, coord, texture_resolution).r;
    }

    // Solves the equation x^3+p*x=p
    float cubic1(float p) 
    {
        float Q=p/3.0;
        float R=p/2.0;
        float D=cube(Q)+square(R);

        if (D<0.0) {
            float theta=acos(R/sqrt(-cube(Q)));
            float res=1e18;
            float Qsqrt=2.0*sqrt(-Q);
            for (int i=0; i<3; i++) {
                float r=Qsqrt*cos((theta+float(i)*2.0*PI)/3.0);
                if (r>0.0 && r<res) 
                {
                    res=r;
                }
            }
            return res;
        }

        float v=-p;

        float vsq=v*v;
        float qo3=p/3.0;
        float uo3=qo3;
        float u2o3=uo3+uo3;
        float uo3sq4=u2o3*u2o3;
        float uo3cu4=uo3sq4*uo3;
        float wsq=uo3cu4+vsq;

        float mcube, n;
        if (v<=0.0) 
        {
            mcube = (-v+sqrt(wsq))/2.0;
        }
        else 
        {
            mcube=(-v-sqrt(wsq))/2.0;
        }
        float m=mcube>0.0 ? pow(mcube, 1.0/3.0) : -pow(-mcube, 1.0/3.0);
        if (m!=0.0) 
        {
            n=-uo3/m ;
        }
        else 
        {
            n=0.0;
        }
        return m+n;
    }

    // Modifies the ray target point to account for cubic distortion.
    // Returns false iff the ray is to be rejected.
    bool apply_cubic_distortion(
        float cubic_distortion_amount, 
        // Film position, where width is normally in [-0.5, 0.5] range (but can be outside thanks to film offset)
        float2 film_position, 
        inout float3 ray_target)
    {
        // Calculate position on film plane, in [-1, 1] (though we can be out of bounds, if a film offset is applied)
        float2 film_uv = film_position * 2.0;

        float r = cubic_distortion_amount * (square(film_uv.x) + square(film_uv.y));
        if(abs(r) > 1e-12)     // Avoid numerical instability: values very close to the center don't get distorted
        {
            float f = cubic1(1.0 / r);
            if(f > 1e-6)        // Rays that are basically parallel to the film plane get clipped
            {
                ray_target.z /= f;
            }
            else
            {
                // Distortion has clipped this ray - reject the sample
                return false;
            }
        }

        return true;
    }

    float square(float v)
    {
        return v * v;
    }

    float cube(float v)
    {
        return v * v * v;
    }
}